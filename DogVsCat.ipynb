{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Line magic function `%matplotllib` not found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotllib inline\n",
    "import os\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from  datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing import image, sequence\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Activation, Dense, Flatten, Reshape,ZeroPadding2D,Dropout\n",
    "from keras.models import Sequential,Model\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specifying number of categories in our data there is 2 dog and cat\n",
    "no_of_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapath = '/my_data/PetImages/'\n",
    "files = os.listdir(datapath)\n",
    "# print files\n",
    "paths = []\n",
    "labels = []\n",
    "for f in files:\n",
    "    if f == '.DS_Store':\n",
    "        continue\n",
    "    ims = os.listdir(datapath + f)\n",
    "    \n",
    "    for px in ims:\n",
    "        if px == '.DS_Store':\n",
    "            continue\n",
    "        if px.endswith(\".jpg\"):\n",
    "            paths.append(datapath + f + '/' + px)\n",
    "            labels.append(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle the data to make training more robust\n",
    "paths, labels = shuffle(paths, labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 262146 bytes but only got 0. Skipping tag 2\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/usr/local/lib/python3.5/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 262151 bytes but only got 0. Skipping tag 56\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/usr/local/lib/python3.5/site-packages/PIL/TiffImagePlugin.py:709: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed:  0:01:37.550256\n"
     ]
    }
   ],
   "source": [
    "img = []\n",
    "img_labels = []\n",
    "\n",
    "# I just have taken 10k images due to memory constraints\n",
    "\n",
    "startTime = datetime.now()\n",
    "for path,label in zip(paths[:10000],labels[:10000]):\n",
    "    try:\n",
    "        im = image.load_img(path, target_size=(224,224,3))\n",
    "        im = image.img_to_array(im)\n",
    "        img.append(im)\n",
    "        img_labels.append(label)\n",
    "    except:\n",
    "        pass\n",
    "print (\"Time Elapsed: \",datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9998"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniques, ids = np.unique(img_labels, return_inverse=True)\n",
    "labels = np_utils.to_categorical(ids, len(uniques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open( \"/output/img_list.p\", \"wb\" ) as pickle_f:\n",
    "    pickle.dump(uniques, pickle_f )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9998, 224, 224, 3) (9998, 2)\n"
     ]
    }
   ],
   "source": [
    "X = np.asarray(img)\n",
    "y = np.asarray(labels)\n",
    "print (X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6998, 224, 224, 3) (6998, 2)\n"
     ]
    }
   ],
   "source": [
    "split = int(0.7*X.shape[0])\n",
    "X_train = X[:split]\n",
    "y_train = y[:split]\n",
    "\n",
    "X_val = X[split:]\n",
    "y_val = y[split:]\n",
    "\n",
    "print (X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecturing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VGG_16_fine_tune(weights_path=None):\n",
    "    # Extract Bottleneck features\n",
    "    vgg = VGG16(weights='imagenet', include_top=True, input_shape=(224,224,3))\n",
    "    x = vgg.layers[-2].output\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(no_of_classes, activation='softmax', name='prediction')(x)\n",
    "    model = Model(inputs=vgg.input, outputs=x)\n",
    "    \n",
    "    # Set Bottom layers as non-trainable to reduce computations\n",
    "    for l in model.layers[:-1]:\n",
    "        l.trainable = False\n",
    "    \n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = VGG_16_fine_tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "prediction (Dense)           (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 8,194\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:7: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6998 samples, validate on 3000 samples\n",
      "Epoch 1/1\n",
      "6998/6998 [==============================] - 154s - loss: 0.1732 - acc: 0.9583 - val_loss: 0.0927 - val_acc: 0.9690\n"
     ]
    }
   ],
   "source": [
    "# I have run it for 2+10 epochs\n",
    "startTime = datetime.now()\n",
    "hist = model.fit(X_train, y_train,\n",
    "                nb_epoch=1,\n",
    "                shuffle=True,\n",
    "                batch_size=100,\n",
    "                validation_data=(X_val, y_val))\n",
    "endTime = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model and it's weights\n",
    "model.save_weights(\"/output/model_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  lets train for more iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6998 samples, validate on 3000 samples\n",
      "Epoch 1/5\n",
      "6998/6998 [==============================] - 154s - loss: 0.1292 - acc: 0.9631 - val_loss: 0.1211 - val_acc: 0.9643\n",
      "Epoch 2/5\n",
      "6998/6998 [==============================] - 155s - loss: 0.1073 - acc: 0.9666 - val_loss: 0.0903 - val_acc: 0.9680\n",
      "Epoch 3/5\n",
      "6998/6998 [==============================] - 155s - loss: 0.1010 - acc: 0.9690 - val_loss: 0.0932 - val_acc: 0.9680\n",
      "Epoch 4/5\n",
      "6998/6998 [==============================] - 155s - loss: 0.1065 - acc: 0.9673 - val_loss: 0.1074 - val_acc: 0.9673\n",
      "Epoch 5/5\n",
      "6998/6998 [==============================] - 155s - loss: 0.0811 - acc: 0.9721 - val_loss: 0.1069 - val_acc: 0.9673\n"
     ]
    }
   ],
   "source": [
    "hist2 =  model.fit(X_train, y_train,\n",
    "                nb_epoch=5,\n",
    "                shuffle=True,\n",
    "                batch_size=100,\n",
    "                validation_data=(X_val, y_val))\n",
    "# save model and it's weights\n",
    "model.save_weights(\"/output/model2_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"/output/model2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights can be downloaded from\n",
    "\n",
    "https://www.floydhub.com/viewer/data/uDHLqkRSAS3tMpxpibxP4C/PYVnzvHEbhfSPHRtNznBii/model2_weights.h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
